{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "L_zoCVonvaNE",
        "outputId": "51357027-b8c5-492e-c128-f7539410db19"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Xxoliaxx/Intent_Prediction_with_Reasoning.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pSL18oMMvcmR",
        "outputId": "6e02d9e5-e4b9-453f-ca16-adf8e654ebd1"
      },
      "outputs": [],
      "source": [
        "%cd /content/Intent_Prediction_with_Reasoning\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yBh41n1QvtCK",
        "outputId": "ced5dcb6-7a1b-481b-8320-2539a23c88d3"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/Dao-AILab/flash-attention.git\n",
        "# %cd flash-attention/hopper\n",
        "# !pip install packaging ninja\n",
        "# # Install from PyPI\n",
        "# !pip install flash-attn --no-build-isolation\n",
        "# %cd /content/Intent_Prediction_with_Reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dUmc4YCpv3V3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "id": "Qecn7BiIvxOx"
      },
      "outputs": [],
      "source": [
        "!python dataset/build_trajectory_dataset.py --input-csv dataset/refined_data.csv --output-dir data/user-trajectory-hrm --window-size 5 --train-frac 0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8ITBfQzv5EA",
        "outputId": "5521b627-28a4-492b-be24-46b095b0cb85"
      },
      "outputs": [],
      "source": [
        "!OMP_NUM_THREADS=8 python pretrain.py data_path=data/user-trajectory-hrm epochs=1000000 eval_interval=20000 global_batch_size=256  lr=7e-5 puzzle_emb_lr=7e-5 weight_decay=1.0 puzzle_emb_weight_decay=1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnIHG3XS8_w3",
        "outputId": "ee4fc481-eba0-4b72-f903-9ac5475b6d4a"
      },
      "outputs": [],
      "source": [
        "!OMP_NUM_THREADS=8 CUDA_VISIBLE_DEVICES=0 torchrun --standalone --nproc-per-node 1 evaluate.py checkpoint=\"checkpoints/User-trajectory-hrm ACT-torch/HierarchicalReasoningModel_ACTV1 active-mamba/step_82000\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (intent_hrm)",
      "language": "python",
      "name": "intent_hrm"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
